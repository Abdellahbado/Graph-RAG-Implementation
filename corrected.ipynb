{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We set up the connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "url = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"password\"\n",
    "\n",
    "graph = Neo4jGraph(url=url, username=username, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3.2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_keywords(text: str, top_n: int = 5) -> List[str]:\n",
    "\n",
    "    import re\n",
    "    from collections import Counter\n",
    "\n",
    "    words = re.findall(r\"\\w+\", text.lower())\n",
    "\n",
    "    stop_words = set(\n",
    "        [\n",
    "            \"the\",\n",
    "            \"a\",\n",
    "            \"an\",\n",
    "            \"and\",\n",
    "            \"or\",\n",
    "            \"but\",\n",
    "            \"in\",\n",
    "            \"on\",\n",
    "            \"at\",\n",
    "            \"to\",\n",
    "            \"for\",\n",
    "            \"of\",\n",
    "            \"with\",\n",
    "            \"by\",\n",
    "        ]\n",
    "    )\n",
    "    filtered_words = [\n",
    "        word for word in words if word not in stop_words and len(word) > 2\n",
    "    ]\n",
    "\n",
    "    return [word for word, count in Counter(filtered_words).most_common(top_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_pdf(\n",
    "    pdf_path: str, chunk_size: int = 1000, chunk_overlap: int = 200\n",
    ") -> List[Dict]:\n",
    "\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "    pages = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "\n",
    "    splits = text_splitter.split_documents(pages)\n",
    "\n",
    "    processed_chunks = []\n",
    "    for i, chunk in enumerate(splits):\n",
    "        metadata = {\n",
    "            \"chunk_id\": i,\n",
    "            \"source\": pdf_path,\n",
    "            \"page_number\": chunk.metadata.get(\"page\", None),\n",
    "            \"total_length\": len(chunk.page_content),\n",
    "            \"keywords\": _extract_keywords(chunk.page_content),\n",
    "            \"text_preview\": (\n",
    "                chunk.page_content[:100] + \"...\"\n",
    "                if len(chunk.page_content) > 100\n",
    "                else chunk.page_content\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        processed_chunks.append({\"text\": chunk.page_content, \"metadata\": metadata})\n",
    "\n",
    "    return processed_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 1281\n",
      "\n",
      "Chunk 0:\n",
      "Text Preview: grokking\n",
      "Deep \n",
      "Reinforcement \n",
      "Learning\n",
      "Keywords: ['grokking', 'deep', 'reinforcement', 'learning']\n",
      "Page Number: 2\n",
      "\n",
      "Chunk 1:\n",
      "Text Preview: grokking\n",
      "Deep \n",
      "Reinforcement \n",
      "Learning\n",
      "Miguel Morales\n",
      "Foreword by Charles Isbell, Jr.\n",
      "MANNING\n",
      "Shelte...\n",
      "Keywords: ['grokking', 'deep', 'reinforcement', 'learning', 'miguel']\n",
      "Page Number: 4\n",
      "\n",
      "Chunk 2:\n",
      "Text Preview: For online information and ordering of this and other Manning books, please visit\n",
      "www  .manning  .co...\n",
      "Keywords: ['manning', 'this', 'publications', 'designations', 'information']\n",
      "Page Number: 5\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"Grokking Deep Reinforcement Learning by Miguel Morales 1.pdf\"\n",
    "\n",
    "\n",
    "chunks = load_and_process_pdf(pdf_path)\n",
    "\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\nChunk {i}:\")\n",
    "    print(f\"Text Preview: {chunk['metadata']['text_preview']}\")\n",
    "    print(f\"Keywords: {chunk['metadata']['keywords']}\")\n",
    "    print(f\"Page Number: {chunk['metadata']['page_number']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use only a subset of chunks and create a knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_chunks(chunks: List[Dict]):\n",
    "\n",
    "    graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "    create_chunk_query = \"\"\"\n",
    "    MERGE (chunk:Chunk {chunk_id: $chunk_id})\n",
    "    ON CREATE SET \n",
    "        chunk.source = $source,\n",
    "        chunk.page_number = $page_number,\n",
    "        chunk.total_length = $total_length,\n",
    "        chunk.text_preview = $text_preview,\n",
    "        chunk.full_text = $full_text\n",
    "    \n",
    "    // Create keyword nodes and relationships\n",
    "    WITH chunk\n",
    "    UNWIND $keywords AS keyword\n",
    "    MERGE (kw:Keyword {name: keyword})\n",
    "    MERGE (chunk)-[:HAS_KEYWORD]->(kw)\n",
    "    \n",
    "    RETURN chunk\n",
    "    \"\"\"\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        graph.query(\n",
    "            create_chunk_query,\n",
    "            params={\n",
    "                \"chunk_id\": chunk[\"metadata\"][\"chunk_id\"],\n",
    "                \"source\": chunk[\"metadata\"][\"source\"],\n",
    "                \"page_number\": chunk[\"metadata\"][\"page_number\"],\n",
    "                \"total_length\": chunk[\"metadata\"][\"total_length\"],\n",
    "                \"text_preview\": chunk[\"metadata\"][\"text_preview\"],\n",
    "                \"full_text\": chunk[\"text\"],\n",
    "                \"keywords\": chunk[\"metadata\"][\"keywords\"],\n",
    "            },\n",
    "        )\n",
    "\n",
    "\n",
    "create_graph_from_chunks(chunks[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 200\n",
      "\n",
      "Sample chunk: {'c.chunk_id': 0, 'c.text_preview': 'grokking\\nDeep \\nReinforcement \\nLearning', 'keywords': ['learning', 'deep', 'reinforcement', 'grokking']}\n"
     ]
    }
   ],
   "source": [
    "verification_query = \"\"\"\n",
    "MATCH (c:Chunk)\n",
    "RETURN count(c) as chunk_count\n",
    "\"\"\"\n",
    "result = graph.query(verification_query)\n",
    "print(f\"Number of chunks created: {result[0]['chunk_count']}\")\n",
    "\n",
    "sample_query = \"\"\"\n",
    "MATCH (c:Chunk)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "WITH c, collect(k.name) as keywords\n",
    "RETURN c.chunk_id, c.text_preview, keywords\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "result = graph.query(sample_query)\n",
    "print(\"\\nSample chunk:\", result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "    FOR (c:Chunk) REQUIRE c.chunk_id IS UNIQUE\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "embedding_dim = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text: str) -> List[float]:\n",
    "   \n",
    "    try:\n",
    "        embedding = embeddings.embed_query(text)\n",
    "\n",
    "        embedding = [float(x) for x in embedding]\n",
    "\n",
    "        magnitude = sum(x * x for x in embedding) ** 0.5\n",
    "        if magnitude > 0:\n",
    "            embedding = [x / magnitude for x in embedding]\n",
    "\n",
    "        if len(embedding) != embedding_dim:\n",
    "            if len(embedding) < embedding_dim:\n",
    "                embedding.extend([0.0] * (embedding_dim - len(embedding)))\n",
    "            else:\n",
    "                embedding = embedding[:embedding_dim]\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding: {e}\")\n",
    "        return [0.0] * embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/200 chunks\n",
      "Processed 20/200 chunks\n",
      "Processed 30/200 chunks\n",
      "Processed 40/200 chunks\n",
      "Processed 50/200 chunks\n",
      "Processed 60/200 chunks\n",
      "Processed 70/200 chunks\n",
      "Processed 80/200 chunks\n",
      "Processed 90/200 chunks\n",
      "Processed 100/200 chunks\n",
      "Processed 110/200 chunks\n",
      "Processed 120/200 chunks\n",
      "Processed 130/200 chunks\n",
      "Processed 140/200 chunks\n",
      "Processed 150/200 chunks\n",
      "Processed 160/200 chunks\n",
      "Processed 170/200 chunks\n",
      "Processed 180/200 chunks\n",
      "Processed 190/200 chunks\n",
      "Processed 200/200 chunks\n"
     ]
    }
   ],
   "source": [
    "def create_vector_index(chunks: List[Dict]):\n",
    "\n",
    "    try:\n",
    "        graph.query(\n",
    "            \"\"\"\n",
    "            DROP INDEX chunk_vector_index IF EXISTS \n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "        graph.query(\n",
    "            \"\"\"\n",
    "            CALL db.index.vector.createNodeIndex(\n",
    "                'chunk_vector_index',\n",
    "                'Chunk',\n",
    "                'embedding',\n",
    "                $dim,\n",
    "                'cosine'\n",
    "            )\n",
    "            \"\"\",\n",
    "            params={\"dim\": embedding_dim},\n",
    "        )\n",
    "\n",
    "        batch_size = 10\n",
    "        total_processed = 0\n",
    "\n",
    "        for i in range(0, len(chunks), batch_size):\n",
    "            batch = chunks[i : i + batch_size]\n",
    "            batch_embeddings = []\n",
    "\n",
    "            for chunk in batch:\n",
    "                embedding = generate_embedding(chunk[\"text\"])\n",
    "                batch_embeddings.append(\n",
    "                    {\"chunk_id\": chunk[\"metadata\"][\"chunk_id\"], \"embedding\": embedding}\n",
    "                )\n",
    "\n",
    "            batch_update_query = \"\"\"\n",
    "            UNWIND $batch AS item\n",
    "            MATCH (chunk:Chunk {chunk_id: item.chunk_id})\n",
    "            SET chunk.embedding = item.embedding\n",
    "            \"\"\"\n",
    "\n",
    "            graph.query(batch_update_query, params={\"batch\": batch_embeddings})\n",
    "\n",
    "            total_processed += len(batch)\n",
    "            print(f\"Processed {total_processed}/{len(chunks)} chunks\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating vector index: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "try:\n",
    "    create_vector_index(chunks[:200])\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create vector index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_vector_index():\n",
    "    query = \"\"\"\n",
    "    SHOW INDEXES\n",
    "    YIELD name, type, labelsOrTypes, properties, options\n",
    "    WHERE name = 'chunk_vector_index'\n",
    "    \"\"\"\n",
    "    return graph.query(query)\n",
    "\n",
    "\n",
    "def vector_search(query: str, top_k: int = 3) -> List[Dict]:\n",
    "   \n",
    "    try:\n",
    "        query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "        search_query = \"\"\"\n",
    "        MATCH (c:Chunk)\n",
    "        WITH c, vector.similarity.cosine(c.embedding, $embedding) AS score\n",
    "        WHERE score > 0.7\n",
    "        RETURN \n",
    "            c.chunk_id AS chunk_id,\n",
    "            c.source AS source,\n",
    "            c.page_number AS page_number,\n",
    "            c.text_preview AS text_preview,\n",
    "            c.full_text AS full_text,\n",
    "            c.total_length AS total_length,\n",
    "            score\n",
    "        ORDER BY score DESC\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "\n",
    "        results = graph.query(\n",
    "            search_query, params={\"embedding\": query_embedding, \"limit\": top_k}\n",
    "        )\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Vector search error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'chunk_vector_index', 'type': 'VECTOR', 'labelsOrTypes': ['Chunk'], 'properties': ['embedding'], 'options': {'indexProvider': 'vector-2.0', 'indexConfig': {'vector.hnsw.m': 16, 'vector.hnsw.ef_construction': 100, 'vector.dimensions': 3072, 'vector.similarity_function': 'COSINE', 'vector.quantization.enabled': True}}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 0,\n",
       "  'source': 'Grokking Deep Reinforcement Learning by Miguel Morales 1.pdf',\n",
       "  'page_number': 2,\n",
       "  'text_preview': 'grokking\\nDeep \\nReinforcement \\nLearning',\n",
       "  'full_text': 'grokking\\nDeep \\nReinforcement \\nLearning',\n",
       "  'total_length': 38,\n",
       "  'score': 0.8552869558334351},\n",
       " {'chunk_id': 97,\n",
       "  'source': 'Grokking Deep Reinforcement Learning by Miguel Morales 1.pdf',\n",
       "  'page_number': 49,\n",
       "  'text_preview': '26 Chapter 1  I  Introduction to deep reinforcement learning\\nThe examples in these chapters are repe...',\n",
       "  'full_text': '26 Chapter 1  I  Introduction to deep reinforcement learning\\nThe examples in these chapters are repeated throughout agents of the same type to make \\ncomparing and contrasting agents more accessible. You still explore fundamentally different \\nkinds of problems, from small, continuous to image-based state spaces, and from discrete to \\ncontinuous action spaces. But, the book’s focus isn’t about modeling problems, which is a \\nskill of its own; instead, the focus is about solving already modeled environments.\\nComparison of different algorithmic \\napproaches to deep reinforcement learning\\nPolicy-based Derivative-free Actor-critic Value-based Model-basedLess sample  efficiency\\n More sample efficiency\\nLess computationally expensive\\n More computationally expensive\\nLess direct learning\\n More direct learning\\nMore direct use of learned function\\n Less direct use of learned function\\n(1) In this book you learn about all these algorithmic approaches to deep',\n",
       "  'total_length': 954,\n",
       "  'score': 0.8088057041168213},\n",
       " {'chunk_id': 50,\n",
       "  'source': 'Grokking Deep Reinforcement Learning by Miguel Morales 1.pdf',\n",
       "  'page_number': 30,\n",
       "  'text_preview': 'What is deep reinforcement learning?  7\\nDeep reinforcement learning agents  \\ncan solve problems that...',\n",
       "  'full_text': 'What is deep reinforcement learning?  7\\nDeep reinforcement learning agents  \\ncan solve problems that require intelligence\\nOn the other side of the agent is the environment . The environment is everything outside the \\nagent; everything the agent has no total control over. Again, imagine you’re training a robot \\nto pick up objects. The objects to be picked up, the tray where the objects lay, the wind, and \\neverything outside the decision maker are part of the environment. That means the robot \\narm is also part of the environment because it isn’t part of the agent. And even though the \\nagent can decide to move the arm, the actual arm movement is noisy, and thus the arm is part \\nof the environment.\\nThis strict boundary between the agent  and the environment is counterintuitive at first, \\nbut the decision maker, the agent, can only have a single role: making decisions. Everything \\nthat comes after the decision gets bundled into the environment.\\nBoundary between agent and environment',\n",
       "  'total_length': 992,\n",
       "  'score': 0.7899357676506042}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(verify_vector_index())\n",
    "results = vector_search(\"what is the definition of deep reinforcement learning\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
    "    embedding=embeddings,  \n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    index_name='chunk_vector_index',  \n",
    "    node_label='Chunk',  \n",
    "    text_node_properties=['full_text'], \n",
    "    embedding_node_property='embedding'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = neo4j_vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Markov Decision Process (MDP) is a mathematical model used in decision-making problems under uncertainty, characterized by its state space S, action space A, transition function T, reward signal R, initial state distribution Sθ, discount factor γ, and horizon H.\\n\\nThanks for asking!'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Initialize the Ollama model\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"what is a markov decision process?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
